\documentclass[11pt,twoside]{article}
\usepackage[american]{babel}
\usepackage{times,subeqnarray}
\usepackage{url}
%\usepackage{lineno}
% following is for pdflatex vs. old(dvi) latex
\newif\myifpdf
\ifx\pdfoutput\undefined
%  \pdffalse           % we are not running PDFLaTeX
   \usepackage[dvips]{graphicx}
\else
   \pdfoutput=1        % we are running PDFLaTeX
%  \pdftrue
   \usepackage[pdftex]{graphicx}
\fi
\usepackage{apatitlepages}
% if you want to be more fully apa-style for submission, then use this
%\usepackage{setspace,psypub,ulem}
\usepackage{setspace} % must come before psypub
%\usepackage{psypub}
\usepackage{psydraft}
%\usepackage{one-in-margins}  % use instead of psydraft for one-in-margs
\usepackage{amsmath} % (JLR) Neede for "cases" in PredNet section
\usepackage[natbibapa]{apacite}   % natbib
% \usepackage{csquotes}  % biblatex
% \usepackage[style=apa]{biblatex}
\input netsym
\usepackage{enumitem}

% tell pdflatex to prefer .pdf files over .png files!!
\myifpdf
  \DeclareGraphicsExtensions{.pdf,.eps,.png,.jpg,.mps,.tif}
\fi

% use 0 for psypub format 
\parskip 2pt
% for double-spacing, determines spacing 
% \doublespacing
% \setstretch{1.5}
\columnsep .25in   % 3/8 in column separation

\def\myheading{ Deep Predictive Learning }

% no twoside for pure apa style, use \markright with heading only
\pagestyle{myheadings}
\markboth{\hspace{.5in} \myheading \hfill}{\hfill O'Reilly et al. \hspace{.5in}}

\def\mytitle{ Deep Predictive Learning in Neocortex and Pulvinar}

\def\myauthor{Randall C. O'Reilly, Jacob L. Russin, Maryam Zolfaghar, and John Rohrlich\\
  Department of Psychology, Computer Science, and Center for Neuroscience \\
  University of California Davis \\
  1544 Newton Ct\\
  Davis, CA 95618\\
  {\small oreilly@ucdavis.edu}\\}

% Please add here a significance statement to explain the relevance of your work
% \significancestatement{We present a significant advance in understanding how the human brain learns, based on the idea that canonical circuits between the neocortex and thalamus drive alternating phases of prediction and bottom-up outcomes, and the resulting prediction errors (as differences in activation states over time) can drive powerful learning.  Critically, we show for the first time that learning based solely on predicting raw visual inputs can generate higher-level abstract categorical representations of 3D objects, which previously has required explicit human-labeled training.  This captures the seemingly magic way in which human learning can create knowledge out of raw experience, without explicit teaching.}

% Please include corresponding author, author contribution and author declaration information
% \authorcontributions{RCO developed the model, performed the non-PredNet simulations, and drafted the paper. JLR performed the PredNet simulations and analysis, and edited the paper.  JR contributed to developing the model and edited the paper.}
% \authordeclaration{R. C. O'Reilly is Chief Scientist at eCortex, Inc., which may derive indirect benefit from the work presented here.}
% \correspondingauthor{\textsuperscript{1}To whom correspondence should be addressed. E-mail: oreilly@ucdavis.edu}

% Keywords are not mandatory, but authors are strongly encouraged to provide them. If provided, please include two to five keywords, separated by the pipe symbol, e.g:
% \keywords{Computational Modeling $|$ Predictive Learning $|$ Object Recognition $|$ Pulvinar $|$ Neocortex } 

\def\mynote{
We thank Dean Wyatte, Tom Hazy, Seth Herd, Kai Krueger, Tim Curran, David Sheinberg, Lew Harvey, Jessica Mollick, Will Chapman, Helene Devillez, and the rest of the CCN Lab for many helpful comments and suggestions.
Supported by: ONR grants ONR N00014-19-1-2684 / N00014-18-1-2116, N00014-14-1-0670 / N00014-16-1-2128, N00014-18-C-2067, N00014-13-1-0067, D00014-12-C-0638.  This work utilized the Janus supercomputer, which is supported by the National Science Foundation (award number CNS-0821794) and the University of Colorado Boulder. The Janus supercomputer is a joint effort of the University of Colorado Boulder, the University of Colorado Denver and the National Center for Atmospheric Research.
All data and materials will be available at \url{https://github.com/ccnlab/deep-obj-cat} upon publication.}

\def\myabstract{
How does the human brain learn new concepts from raw sensory experience, without explicit instruction?  We still do not have a widely-accepted answer to this central question.  Here, we propose a detailed biological mechanism for the widely-embraced idea that learning is based on the differences between predictions and actual outcomes (i.e., \emph{predictive error-driven learning}).  Specifically, numerous weak projections into the pulvinar nucleus of the thalamus generate top-down predictions, and sparse, focal \emph{driver} inputs from lower areas supply the actual outcome, originating in layer 5 intrinsic bursting (5IB) neurons.  Thus, the outcome is only briefly activated, roughly every 100 msec (i.e., 10 Hz, \emph{alpha}), resulting in a \emph{temporal difference error signal}, which drives local synaptic changes throughout the neocortex, resulting in a biologically-plausible form of error backpropagation learning.  We implemented these mechanisms in a large-scale model of the visual system, and found that the simulated inferotemporal (IT) pathway learns to systematically categorize 3D objects according to invariant shape properties, based solely on predictive learning from raw visual inputs.  These categories match human judgments on the same stimuli, and are consistent with neural representations in IT cortex in primates.
}

\begin{document}
\bibliographystyle{apacite}

% sloppy is the way to go!
% \sloppy
% \raggedbottom

\titlesepage{\mytitle}{\myauthor}{\mynote}{\myabstract}

% todo:
% * include deep\_fsa model description first!  why not?  also pointer to sg.

\pagestyle{myheadings}

The fundamental epistemological conundrum of how knowledge emerges from raw experience has challenged philosophers and scientists for centuries.  There have been significant advances in cognitive and computational models of learning \citep{AshbyMaddox11,WatanabeSasaki15,LeCunBengioHinton15} and in our understanding of the detailed biochemical basis of synaptic plasticity \citep{LuscherMalenka12,ShouvalBearCooper02,CooperBear12,UrakuboHondaFroemkeEtAl08}.  However, there is still no widely-accepted answer to this puzzle that is clearly supported by known biological mechanisms and also produces effective learning at the computational and cognitive levels.  At these functional levels, the idea that we learn via an active \emph{predictive} process goes back to Helmholtz's \emph{recognition by synthesis} proposal \citep{Helmholtz13}, and has been widely embraced in a wide range of different frameworks \citep{Elman90,ElmanBatesKarmiloff-SmithEtAl96,Mumford92,KawatoHayakawaInui93,DayanHintonNealEtAl95,RaoBallard99,Friston05,HawkinsBlakeslee04,GeorgeHawkins09,Clark13,SummerfielddeLange14,deLangeHeilbronKok18}.  Here, we propose a detailed biological mechanism for a specific form of \emph{predictive error-driven learning} based on distinctive patterns of connectivity between the neocortex and the pulvinar nucleus of the thalamus \citep{ShermanGuillery06,UsreySherman18}.

Specifically, we hypothesize that learning is based on the difference between top-down predictions, generated by numerous weak projections into the thalamic relay cells (TRCs) in the pulvinar, and the actual outcomes supplied by sparse, focal, strong \emph{driver} inputs from lower areas.  Because these driver inputs originate in layer 5 intrinsic bursting (5IB) neurons, the outcome is only briefly activated, roughly every 100 msec (i.e., 10 Hz, \emph{alpha}).  Thus, the prediction error is a \emph{temporal difference} in activation states over the pulvinar, from an earlier prediction to a subsequent burst of outcome.  This temporal difference can drive local synaptic changes throughout the neocortex, supporting a biologically-plausible form of error backpropagation to improve the predictions over time \citep{OReilly96,AckleyHintonSejnowski85,HintonMcClelland88,BengioMesnardFischerEtAl17,WhittingtonBogacz19,LillicrapSantoroMarrisEtAl20}. 
The temporal-difference form of error-driven learning contrasts with prevalent alternative hypotheses that require a separate population of neurons to compute a prediction error ``explicitly'' and transmit it directly through neural firing \citep{RaoBallard99,KawatoHayakawaInui93,Friston05,Friston10,OudenKokLange12,LotterKreimanCox16}.

In the following, our primary objective is to describe the hypothesized biologically-based mechanism for predictive error-driven learning, contrast it with other existing proposals regarding the functions of this thalamocortical circuitry and other ways that the brain might support predictive learning, and evaluate it relative to a wide range of existing anatomical and electrophysiological data.  We provide a number of specific empirical predictions that follow from this functional view of the thalamocortical circuit, which could potentially be tested by current neuroscientific methods.  Thus, this work proposes a clear functional interpretation of this distinctive thalamocortical circuitry that contrasts with existing ideas in testable ways. 

A second major objective is to implement this predictive error-driven learning mechanism in a large-scale computational model that faithfully captures its essential biological features, to test whether the proposed learning mechanism can drive the formation of cognitively-useful representations.  In particular, we ask a critical question for any purely predictive-learning model: can it develop high-level, abstract representations while learning from nothing but predicting low-level visual inputs.  For example, most visual object recognition models that provide a reasonable fit to neurophysiological data rely on large human-labeled image datasets to explicitly train abstract category information via error-backpropagation \citep{CadieuHongYaminsEtAl14,Khaligh-RazaviKriegeskorte14,RajalinghamIssaBashivanEtAl18}.

Through large-scale simulations based on the known structure of the visual system, we found that our biologically based predictive learning mechanism developed high-level abstract representations that significantly diverge from the similarity structure present in the lower layers of the network, and systematically categorize 3D objects according to invariant shape properties.  Furthermore, we found in a similarity judgment experiment that these categories match human judgments on the same stimuli, and that they are also qualitatively consistent with neural representations in inferotemporal (IT) cortex in primates \citep{CadieuHongYaminsEtAl14}.  In addition, we show that comparison predictive backpropagation models lacking these biological features \citep{LotterKreimanCox16} did not learn object categories that go beyond the visual input structure.  Thus, there may be some important features of the biologically-based model that enable this ability to learn higher-level structure beyond that of the raw inputs.

It is important to emphasize that our objectives in this work are \emph{not} to produce a better machine-learning (ML) algorithm \emph{per se}, but rather to test the computational properties of our biologically-based, scientific theory for how the mammalian brain might learn.  Thus, we explicitly dissuade readers from the inevitable desire to evaluate the importance of our model based on differences in narrow, performance-based ML metrics: it should instead be evaluated on its ability to explain a wide range of data across multiple levels of analysis, just as every other scientific theory is evaluated.

The remainder of the paper is organized as follows.  First, we provide a concise overview of the biologically based predictive error-driven learning framework, including the most relevant neural data.  Then, we present a small-scale implementation of the model that learns a probabilistic grammar, to help understand its basic computational properties, followed by the large-scale model of the visual system, which learns by predicting over brief visual movies of 3D objects rotating and translating in space.  We evaluate this model and compare it to two other prediction-error learning models that use pure error-backpropagation, based on current deep-convolutional neural network (DCNN) principles.  Then, we circle back to discuss the relevant biological data in greater detail, along with testable predictions that can differentiate this account from other existing ideas.  Finally, we conclude with a discussion of related models and outstanding issues.

\section{Predictive Error-driven Learning in the Neocortex and Pulvinar}

\begin{figure}
  \centering\includegraphics[width=4in]{figs/fig_sherman_guillery_summary}
  \caption{\footnotesize Summary figure from Sherman \& Guillery (2006) showing the strong feedforward driver projection emanating from layer 5IB cells in lower layers (e.g., V1), and the much more numerous feedback ``modulatory'' projection from layer 6CT cells.  We interpret these same connections as providing a prediction (6CT) vs. outcome (5IB) activity pattern over the pulvinar.}
  \label{fig.sg06}
\end{figure}

\begin{figure}
  \centering\includegraphics[width=6in]{figs/fig_deepleabra_v1v2_time}
  \caption{\footnotesize Temporal evolution of information flow under our predictive learning hypothesis, over a sequence of movie frames (Retina), illustrating the three key steps taking place within a single 125 msec time window, broken out separately across the three panels: {\bf a)} prior context is updated in the V2 CT layer; {\bf b)} which is then used to generate a prediction over the pulvinar (V2 P); {\bf c)} against which the outcome, driven by bottom-up 5IB bursting, represents the prediction error, \emph{as a temporal difference between the prediction and outcome states over the pulvinar}. Changes in synaptic weights (learning) in all superficial (S) and CT layers are driven from the \emph{local} temporal difference experienced by each neuron, using a form of the contrastive hebbian learning (CHL) term as shown, where the $+$ superscripts indicate outcome activations, and $-$ superscripts indicate prediction. CHL approximates the backpropagated prediction error gradient experienced by each neuron (O'Reilly, 1996), reflecting both direct pulvinar error signals, and indirect corticocortical error signals as well.  In specific: {\bf a)} CT context updating occurs via 5IB bursting (not shown) in higher layer (V2) during prior alpha (100 msec) cycle --- this context is maintained in the CT layer and used to generate predictions. {\bf b)} The prediction over pulvinar is generated via numerous top-down CT projections. This prediction state also projects up to S and CT layers, and from S to all other S layers via extensive bidirectional connectivity, so their activation state reflects this prediction as well.  {\bf c)} The subsequent outcome drives pulvinar activity bottom-up via V1 5IB bursting, and is likewise reflected in S and CT layers, ensuring that the relevant temporal difference error signal is available locally. The difference in activation values across these two time points, in S and CT layers throughout the network, drives learning to reduce prediction errors.}
  \label{fig.dltime}
\end{figure}

Figure~\ref{fig.sg06} shows the thalamocortical circuits characterized by \citet{ShermanGuillery06} (see also \citealp{ShermanGuillery13,UsreySherman18}), which have two distinct projections converging on the principal thalamic relay cells (TRCs) of the \emph{pulvinar}, the primary thalamic nucleus that is interconnected with higher-level posterior cortical visual areas \citep{Shipp03,ArcaroPinskKastner15,HalassaKastner17}.  One projection consists of numerous, weaker connections originating in deep layer VI of the neocortex (the 6CT corticothalamic projecting cells), which we hypothesize generate a top-down prediction on the pulvinar.  The other is a sparse, focal \citep{Rockland98a,Rockland96} and strong \emph{driver} pathway that originates from lower-level layer 5 intrinsic bursting cells (5IB), which we hypothesize provide the outcome.  These 5IB neurons fire discrete bursts with intrinsic dynamics having a period of roughly 100 msec between bursts \citep{ConnorsGutnickPrince82,SilvaAmitaiConnors91,LarkumZhuSakmann99,FranceschettiGuatteoPanzicaEtAl95,SaalmannPinskWangEtAl12}, which is thought to drive the widely-studied \emph{alpha} frequency of 10 Hz that originates in cortical deep layers and has important effects on a wide range of perceptual and attentional tasks \citep{BuffaloFriesLandmanEtAl11,VanRullenKoch03,MathewsonGrattonFabianiEtAl09,JensenBonnefondVanRullen12,ClaytonYeungKadosh18}.  Critically, unlike many other such bursting phenomena, this 5IB bursting occurs in awake animals \citep{LuczakBarthoHarris09,LuczakBarthoHarris13,SakataHarris09,SakataHarris12}, consistent with presence of alpha in awake behaving states.

The existing literature generally characterizes the 6CT projection as \emph{modulatory} \citep{ShermanGuillery13,UsreySherman18}, but a number of electrophysiological recordings from awake, behaving animals clearly show sustained, continuous patterns of neural firing in pulvinar TRC neurons, which is not consistent with the idea that they are only being driven by their phasic bursting 5IB inputs \citep{Bender82,PetersenRobinsonKeys85,BenderYouakim01,Robinson93,SaalmannPinskWangEtAl12,KomuraNikkuniHirashimaEtAl13,ZhouSchaferDesimone16}.  Indeed, these recordings show that pulvinar neural firing generally resembles that of the visual areas with which they interconnect.  This is important because our predictive learning framework requires that these 6CT top-down projections be capable of driving TRC activity directly.  Specifically, in contrast to the standard view, the core idea behind our theory is that the top-down 6CT projections drive a \emph{prediction} across the extent of the pulvinar, which precedes the subsequent \emph{outcome} state driven by the strong 5IB inputs.

Figure~\ref{fig.dltime} illustrates the temporal evolution of activity states according to our predictive learning theory \citep{KachergisWyatteOReillyEtAl14,OReillyWyatteRohrlich14,OReillyWyatteRohrlich17}, which is somewhat challenging to convey because the critical signals driving learning unfold \emph{over time}, and we hypothesize that synaptic plasticity throughout the cortex is sensitive to the resulting \emph{temporal differences} that emerge initially in the pulvinar.  Thus, unlike other models (as we discuss in depth later) the prediction error here is not captured directly in the firing of a special population of error-coding neurons, but rather remains as a temporal difference error signal.

Figure~\ref{fig.dltime} shows a single 125 msec time window of a 100 msec alpha cycle for the purposes of illustration (the actual timing is likely to be more dynamic as discussed next).  The activity state in pulvinar TRC neurons, representing a prediction as driven by the top-down 6CT projections, should develop during the first $\sim$ 75 msec, while the final $\sim$ 25 msec largely reflects the strong 5IB bottom-up ground-truth driver inputs.  Thus, the prediction error signal is reflected in the temporal difference of these activation states as they develop over time.  In other words, our hypothesis is that the pulvinar is directly representing either the top-down prediction or the bottom-up outcome at any given time, and the temporal difference between these states implicitly encodes a prediction error.  While the deep 6CT layer is involved in generating a top-down prediction over the pulvinar, the superficial layer neurons continuously represent the current state, simultaneously incorporating bottom-up and top-down constraints.  To ensure that the prediction is not directly influenced by this current state representation (i.e., ``peeking at the right answer''), it is important that the 6CT neurons encode temporally delayed information, consistent with available data \citep{HarrisShepherd15,SakataHarris09,Thomson10}.

A set of neural mechanisms can work together to enable the system to more flexibly entrain the predictive learning cycle to the environment, and also increase activity and learning associated with unexpected outcomes relative to expected ones.  Specifically, various underlying mechanisms result in neural \emph{adaptation}, which is generally thought to increase neural activity and learning associated with novel inputs relative to recently familiar ones \citep{MullerMethaKrauskopfEtAl99,AbbottVarelaSenEtAl97,BretteGerstner05,Grill-SpectorHensonMartin06,Hennig13}.  In the case where outcomes are consistent with prior predictions (i.e., the predictions are accurate), the same population of neurons across pulvinar and cortex should be active over time, whereas unpredicted outcomes will generally activate new subsets of neurons in superficial cortical layers representing the current state.  Thus, due to adaptation, there should be a phasic increase in activity in these superficial neurons at the onset of unpredicted stimuli relative to predicted ones.

Furthermore, the 5IB neurons downstream of these superficial neurons may be particularly responsive to these phasic activity increases, causing their bursting to coincide preferentially with unexpected outcomes, thereby driving the phase resetting of the alpha cycle to such events.  Thus, during a sequence of predicted states, the pulvinar may experience relatively weaker or even absent 5IB driving inputs, until an unpredicted stimulus arises.  At this point, error-driven learning would be more strongly engaged as a function of the phasic release from adaptation and 5IB burst activation.  We discuss these dynamics more later in the context of the \emph{expectation suppression} phenomena \citep{SummerfieldTrittschuhMontiEtAl08,TodorovicEdeMarisEtAl11,MeyerOlson11,BastosUsreyAdamsEtAl12}.

We also hypothesize that 5IB bursting preferentially drives learning, due the strong driving nature of the outputs from these neurons.  In computational terms originating with the \emph{Boltzmann Machine} \citep{AckleyHintonSejnowski85,HintonSalakhutdinov06}, this anchors the target or \emph{plus} phase to be at this point of 5IB bursting.  Furthermore, this means that the prediction is essentially \emph{defined} as the state prior to 5IB bursting, and the learning rule automatically causes that prior state to better anticipate the subsequent state.  This means that even if no prediction was initially generated, learning over multiple iterations will work to create one, to the extent that a reliable prediction can be generated based on internal states and environmental inputs.  It also means that although the alpha rhythm defines a baseline minimum prediction window, predictive learning could still happen at longer delays (again assuming relevant predictive state information is available to bridge the delay).

In short, learning always happens whenever something unexpected occurs, at any point, and drives the development of predictions immediately prior, to the extent such predictions are possible to generate.  In the typical lab experiment where phasic stimuli are presented without any predictable temporal sequence (which is likely uncharacteristic of the natural world), there may often be no significant prediction prior to stimulus onset, and we would expect such stimuli to reliably drive 5IB bursting, which is consistent with available electrophysiological data \citep{Bender82,PetersenRobinsonKeys85,BenderYouakim01,Robinson93,LuczakBarthoHarris09,LuczakBarthoHarris13,KomuraNikkuniHirashimaEtAl13,ZhouSchaferDesimone16}.

As may be evident by this point, we are mainly focused on \emph{prediction} in the sense of the humorous quote: ``prediction is very difficult, especially about the future'' (attributable to Danish author Robert Storm Petersen), whereas this term is potentially confusingly used in a much broader sense in most Bayesian-inspired predictive coding frameworks \citep{RaoBallard99,Friston05,deLangeHeilbronKok18}.  
These frameworks use ``prediction'' to encompass everything from genetic biases to the results of learning in the feedforward synaptic pathways to top-down filling-in or biasing of the current stimulus properties, and fairly rarely for the ``about the future'' meaning.   We think these different phenomena are each associated with different neural mechanisms at different time scales \citep{OReillyWyatteHerdEtAl13,OReillyMunakataFrankEtAl12}, and thus prefer to treat them separately, while also recognizing that they clearly interact, e.g., with predictive learning hypothesized to be the primary driver of learning of all pathways in the cortex.

Thus, our use of the term \emph{prediction} here refers specifically to \emph{anticipatory} neural firing that predicts subsequent stimuli.  We use the term \emph{postdiction} to refer to the operation of this predictive mechanism after a stimulus has been initially processed (to consolidate and more deeply encode, as in an auto-encoder model), and distinguish both from \emph{top-down excitatory biasing}, which directly influences the online superficial layer neural representations of the current stimulus \citep{DesimoneDuncan95,ReynoldsChelazziDesimone99,MillerCohen01,OReillyWyatteHerdEtAl13}.  Finally, many discussions of prediction error in the literature include late, frontally-associated processes such as those associated with the P300 ERP component \citep{HolroydColes02}.  We specifically exclude these from the scope of the mechanisms described here, which are anticipatory, fast, and low-level, as is appropriate for the posterior cortical sensory processing areas that interconnect with the pulvinar.

\subsection{Computational Properties of Predictive Learning in the Thalamocortical Circuits}

We next elaborate the connections between the computational properties required for predictive learning, and the properties of the thalamocortical circuits in the pulvinar, which appear to be notably well suited for the hypothesized predictive learning role, in the following ways:
\begin{itemize}

	\item Assuming the process of generating a prediction involves the integration of multiple converging inputs from a range of higher-level cortical areas, each encoding different dimensions of relevance (e.g., location, motion, color, texture, shape, etc), sufficient time must be available to perform this integration, along with some kind of dedicated neural substrate upon which it can be performed.  This neural substrate must be distinct from those encoding the continuously evolving representations of the incoming sensory state, assuming that it is not possible to suspend that process during the time it takes to develop the prediction (and thereby re-use the same substrate).  Furthermore, it is likely that prediction generation requires a broader convergence of top-down inputs than is required for sensory state encoding, and any prediction error signal should also be widely broadcast back out to these same areas, to provide the training signal that improves their predictions.  All of these considerations are nicely satisfied by having a separate, compact, broadly integrative, bidirectionally connected nucleus in the form of the pulvinar and its 6CT inputs and reciprocal efferents back out to the neocortex \citep{Shipp03}.  Furthermore, the TRC neurons are distinctive in having no significant lateral interconnectivity \citep{ShermanGuillery06}, enabling them to faithfully represent their inputs.  These properties led \citet{Mumford91} to characterize the pulvinar as a \emph{blackboard}, and we further suggest the metaphor of a \emph{projection screen} upon which the predictions are projected.

	\item The obvious locus for ongoing sensory integration and the online ``current state'' representation is in the superficial lamina of each cortical area.  The pyramidal neurons here are densely and bidirectionally interconnected with other cortical areas, and update rapidly to new stimulus inputs, with continuous, relatively rapid firing (up to about 100 Hz) for preferred stimuli.  These neurons integrate higher-level top-down information with bottom-up sensory information, to fill in missing information, resolve ambiguities, focus attention, and generally enhance the consistency and quality of the online representations \citep{DesimoneDuncan95,ReynoldsChelazziDesimone99,MillerCohen01,OReillyWyatteHerdEtAl13,OReillyMunakataFrankEtAl12,OReillyHazyHerd16}. As noted above, we distinguish this form of top-down processing, which is often most evident during the period after stimulus onset \citep{LeeMumford03}, from the specifically predictive sort.  However, when the deep layers are predictively anticipating the onset of upcoming stimuli, these top-down deep layer projections will result in pre-activation of anticipated stimuli over superficial layers in addition to the pulvinar.

	\item Each cortical area requires a distinct population of neurons to generate its contribution to the overall prediction, for reasons that will become clear in a moment. With the superficial neurons occupied by the current state, this naturally leaves the deep lamina neurons as the logical substrate for this job, particularly the 6CT population that projects directly and exclusively to the pulvinar.  Thus, this framework also provides a clear functional division of labor for the superficial and deep neocortical lamina (with layer 4 stellates providing a localized input processing function).
	
	\item A true prediction (about the future) must be prevented from cheating and relying on direct information about that which is being predicted.  Thus there must be a mechanism preventing the new sensory outcome information continuously encoded in the superficial layers from ``contaminating'' the prediction-generation components in the deep layers and pulvinar.  The phasic, bursting nature of the 5IB driver inputs provides this essential feature, creating a window where no outcome signals are impinging on the pulvinar, when the prediction can be represented.  The prediction and current state synchronize at the moment of the 5IB driver bursting.  Furthermore, the activity in the 6CT deep layers that generates the top-down predictions over the pulvinar is itself driven by 5IB neuron bursting within the local columnar circuits of these higher level areas, such that these prediction-generating neurons are also kept isolated from current superficial-layer activation (Figure~\ref{fig.dltime}).  Biologically, this is consistent with the delayed responses of 6CT neurons \citep{HarrisShepherd15,SakataHarris09,Thomson10}.  Computationally, this functions much like the simple recurrent network (SRN) context layer updating \citep{Elman90,Jordan89} which reflects the prior trial's state, as shown in the Appendix.  Interestingly, by these principles, the lack of bursting in the driver inputs to first-order sensory thalamus areas \citep{ShermanGuillery06} means that these areas should not be directly capable of error-driven predictive learning, but they do receive ``collateral'' error signals from the pulvinar \citep{Shipp03}, which could provide some useful indirect error-driven learning signals.

	\item The outcome signal should be as \emph{veridical} as possible (i.e., directly reflecting the bottom-up outcome), and should arise from lower areas in the hierarchy relative to the corresponding 6CT inputs: the bottom-up, sparse, focal, strongly driving nature of the 5IB projections can directly convey such veridical outcome signals, and ensure that they dominate the activation of their TRC targets.  Based on indirect available data, it is likely that each pulvinar TRC neuron receives only roughly 1-6 driver inputs \citep{ShermanGuillery06,ShermanGuillery11}.  Furthermore, these inputs are likely not plastic \citep{UsreySherman18} --- they drive plasticity, and are thus not subject to it. 

		\item The integration required to generate the prediction should take more time than the outcome phase, which is consistent with a relatively brief period of 5IB bursting (roughly 25 msec or less; \citealp{ConnorsGutnickPrince82}), leaving approximately 75 msec of a nominal 100 msec alpha cycle for this integration.  The overall duration of the alpha cycle itself may represent a reasonable compromise between this integration time and the need to keep up with predictions tracking changes in the world.

	\item For cortical neurons receiving projections from the pulvinar, there must be some way in which the difference between prediction and outcome (i.e., the error itself) can drive learning.  Here we hypothesize that this difference remains as a \emph{temporal difference} error signal, i.e., the difference over time in pulvinar activation states, arising naturally as a prediction state followed by the outcome state.  This contrasts with prevalent alternative hypotheses that require a separate population of neurons to compute a prediction error ``explicitly'' and transmit it directly through neural firing, as we discuss later.  We argue that a temporal-difference prediction error signal is more natural, efficient, and consistent with bidirectional excitatory connectivity between cortical areas \citep{RumelhartMcClelland82,Hopfield84,DesimoneDuncan95,ReynoldsChelazziDesimone99,MillerCohen01,OReillyWyatteHerdEtAl13}.  Note that this form of temporal-difference learning signal is distinct from the widely-used TD model in reinforcement learning \citep{SuttonBarto98}, which is scalar, and applies to reward expectations, not sensory predictions (although see \citealp{GardnerSchoenbaumGershman18} and \citealp{Dayan93} for potential connections between these two forms of prediction error).

	\item There is a long history of computational models of error-driven learning based on temporal-difference signals \citep{AckleyHintonSejnowski85,OReilly96,BengioMesnardFischerEtAl17,WhittingtonBogacz19,LillicrapSantoroMarrisEtAl20}, and we have recently provided a direct biological mechanism for this form of learning \citep{OReillyMunakataFrankEtAl12}, based on a biologically-detailed model of spike timing dependent plasticity (STDP) \citep{UrakuboHondaFroemkeEtAl08}.  We showed that when activated by realistic Poisson spike trains, this STDP model produces a non-monotonic learning curve similar to that of the BCM model \citep{BienenstockCooperMunro82}, which results from competing calcium-driven postsynaptic plasticity pathways \citep{ShouvalBearCooper02,CooperBear12}.  As in the BCM framework, we hypothesized that the threshold crossover point in this nonmonotonic curve moves dynamically --- if this happens on the alpha timescale \citep{LimMcKeeWoloszynEtAl15}, then it can reflect the prediction phase of activity, producing a net error-driven learning rule based on a subsequent calcium signal reflecting the outcome state.  This form of error-driven learning mathematically approximates backpropagation gradient descent to minimize overall prediction errors \citep{OReilly96}.
\end{itemize}

Thus, remarkably, the pulvinar and associated thalamocortical circuitry appears to provide \emph{precisely} the necessary ingredients to support predictive error-driven learning.  Interestingly, although \citet{ShermanGuillery06} did not propose a predictive learning mechanism as just described, they did speculate about a potential role for this circuit in motor forward-model learning and the predictive remapping phenomenon \citep{ShermanGuillery11,UsreySherman18}.  In addition, \citet{PennartzDoraMuckliEtAl19} also suggested that the pulvinar may be involved in predictive learning, but within the explicit error-coding framework and not involving the detailed aspects of the above-described circuitry.  

As we discuss later, this proposed predictive role for the pulvinar is not incompatible with the more widely-discussed role it may play in attention \citep{LaBergeBuchsbaum90,BenderYouakim01,SnowAllenRafalEtAl09,SaalmannKastner11,ZhouSchaferDesimone16,FiebelkornKastner19}.  Indeed, we think these two functions are synergistic (i.e., you predict what you attend, and vice-versa; \citealp{RichterdeLange19}), and have initial computational results consistent with this idea.

\section{Predictive Learning of Temporal Structure in a Probabilistic Grammar}

\begin{figure}
  \centering\includegraphics[width=2.5in]{figs/fig_reber_grammar_fsa}
  \caption{\footnotesize Finite state automaton (FSA) grammar used in implicit sequential learning exerpiments (Reber, 1967) and in early simple recurrent networks (SRNs) (Cleeremans \& McClelland, 1991).  It generates a sequence of letters according to the link transitioned between state nodes, with a 50\% random choice for each node of which outgoing link to follow.  Each letter (except for the B=begin and E=end) appears at 2 different points in the grammar, making them fully ambiguous.  This combination of randomness and ambiguity makes it challenging for a learning system to infer the true underlying nature of the grammar.}
  \label{fig.fsa_grammar}
\end{figure}

\begin{figure}
  \centering\includegraphics[width=3.5in]{figs/fig_deepleabra_fsa_net_3steps}
  \caption{\footnotesize Predictive learning model applied to the FSA grammar shown in previous figure, showing the prediction state (end of the {\em minus} phase, or the first 75 msec of each alpha cycle) for the first 3 steps of a sequence, after having learned the grammar, followed by the plus phase after the third step.  The {\em Input} layer provides the 5IB drivers for the corresponding {\em HiddenP} pulvinar layer, and the {\em Targets} layer is purely for display, showing the two valid possible labels that could have been predicted.  The model's prediction is scored as accurate if either or both targets are activated.  Computationally, the model is similar to the SRN, where the CT layer that drives the prediction over the pulvinar encodes the previous time step (alpha cycle) activation state, due to the phasic bursting of the 5IB neurons that drive CT updating.  Note how the CT layer in b) reflects the Hidden activation state in a), and likewise for c) reflecting b) --- this is evident because we're using one-to-one connectivity between Hidden and HiddenCT layers (which works well in general, along with full lateral connectivity within the CT layer).  Thus, even though the correct answer is always present on the Input layer for each step, the CT layer is nevertheless attempting to predict this Input based on the information from the prior time step.  {\bf a)} In the first step, the B label is unambiguous and easily predicted (based on prior E context). {\bf b)} In the 2nd step, the network correctly guesses that the T label will come next, but there is a faint activation of the other P alternative, which is also activated sometimes based on prior learning history and associated minor weight tweaks.  {\bf c)} In the 3rd step, both S and X are equally predicted.  {\bf d)} In the {\em plus} phase for this trial, only the X present in the Input  drives HiddenP activations, and the projections from pulvinar back to the cortex convey both the minus-phase prediction and plus-phase actual input.  You can see one neuron visibly changes is activation as a result (and all neurons experience much smaller changes), and learning in all these cortical (Hidden) layer neurons is a function of their local temporal difference between minus and plus phases.}
  \label{fig.fsa_net}
\end{figure}

To illustrate and test the predictive learning abilities of this biologically-based model, we first ran a classical test of sequence learning \citep{Reber67,CleeremansMcClelland91} that has been explored using simple recurrent networks (SRNs) \citep{Elman90,Jordan89}.  The Appendix provides a detailed mapping between the SRN and our biological model.  As shown in Figure~\ref{fig.fsa_grammar}, sequences were generated according to a finite state automaton (FSA) grammar, as used in implicit sequence learning experiments by \citet{Reber67}.  Each node has a 50\% random branching to two different other nodes, and the labels generated by node transitions are ambiguous (except for the B=begin and E=end states).  Thus, many iterations through the grammar are required to infer the systematic underlying grammar, and it is actually a reasonably challenging task for SRNs, and people, to learn, providing an important validation of the power of these predictive learning mechanisms.

Our model (Figure~\ref{fig.fsa_net}) required around 20 epochs of 25 sequences through the grammar to learn it to the point of making no prediction errors for 5 epochs in a row, to guarantee that it had completely learned it.  This model is available in the standard {\em emergent} distribution, at \url{https://github.com/emer/leabra/examples/deep_fsa}.  A few steps through a sequence are shown in the figure, illustrating how the CT context layer, which drives the P pulvinar layer prediction, represents the information present on the {\em previous} alpha cycle time step.  Thus, the network is attempting to predict the actual Input state, which then drives the pulvinar plus phase activation at the end of each alpha cycle, as shown in the last panel.  On each trial, the difference between plus and minus phases locally over each cortical neuron drives its synaptic weight changes, which accumulate over trials to accurately learn to predict the sequences to the extent possible given their probabilistic nature.

\section{Predictive Learning of Object Categories in IT Cortex}

\begin{figure}
  \centering\includegraphics[width=4in]{figs/fig_deepleabra_wwi_ab_pred_model_frames}
  \caption{\footnotesize {\bf a)} The \emph{What-Where-Integration, WWI} deep predictive learning model. The dorsal \emph{Where} pathway learns first, using easily-abstracted \emph{spatial blobs}, to predict object location based on prior motion, visual motion, and saccade efferent copy signals.  This drives strong top-down inputs to lower areas with accurate spatial predictions, leaving the \emph{residual} error concentrated on \emph{What} and \emph{What * Where} integration.  The V3 and DP (dorsal prelunate) constitute the \emph{What * Where} integration pathway, binding features and locations.  V4, TEO, and TE are the \emph{What} pathway, learning abstracted object category representations, which also drive strong top-down inputs to lower areas.  Suffixes: \emph{s} = superficial, \emph{d} = deep, \emph{p} = pulvinar. {\bf c)} Example sequence of 8 alpha cycles that the model learned to predict, with the reconstruction of each image based on the V1 gabor filters (\emph{V1h recon}), and model-generated prediction (correlation $r$ prediction error shown).  The low resolution and reconstruction distortion impair visual assessment, but $r$ values are well above the $r$'s for each V1 state compared to the previous time step (mean = .38, min of .16 on frame 4 --- see Appendix for more analysis).  Eye icons indicate when a saccade occurred.}
  \label{fig.model}
\end{figure}

Now we describe a large-scale, systems-neuroscience implementation of the proposed thalamocortical predictive error-driven learning framework, in a model of visual predictive learning (Figure~\ref{fig.model}).  Our second major objective, and a critical question for predictive learning, is determining whether the model can develop high-level, abstract ways of representing the raw sensory inputs, while learning from nothing but predicting these low-level visual inputs.  We showed the model brief movies of 156 3D object exemplars drawn from 20 different basic-level categories (e.g., car, stapler, table lamp, traffic cone, etc.) selected for their overall shape diversity from the CU3D-100 dataset \citep{OReillyWyatteHerdEtAl13}.  The objects moved and rotated in 3D space over 8 movie frames, where each frame was sampled at the alpha frequency (films are typically shown at just over 2X this frequency, suggesting a Nyquist sampling relative to the underlying alpha processing) (Figure~\ref{fig.model}b).  There were also saccadic eye movements every other frame, introducing an additional, realistic, predictive-learning challenge.  An efferent copy signal enabled full prediction of the effects of the eye movement, and allows the model to capture the signature predictive remapping phenomenon \citep{DuhamelColbyGoldberg92,CavanaghHuntAfrazEtAl10,NeupaneGuittonPack17}.  The \emph{only} learning signal available to the model was the prediction error generated by the temporal difference between what it predicted to see in the V1 input in the next frame and what was actually seen.

As described in detail in the Appendix, our model was constructed to capture critical features of the visual system, including the major division between a dorsal \emph{Where} and ventral \emph{What} pathway \citep{UngerleiderMishkin82}, and the overall hierarchical organization of these pathways derived from detailed connectivity analyses \citep{RocklandPandya79,FellemanVanEssen91,MarkovVezoliChameauEtAl14,MarkovErcsey-RavaszGomesEtAl14}.  In addition to these biological constraints, we conducted extensive exploration of the connectivity and architecture space, and found a remarkable convergence between what worked functionally and the known properties of these pathways \citep{OReillyWyatteRohrlich17}.  For example, the feedforward pathway has projections from lower-level superficial layers to superficial layers of higher levels, while feedback originated in both the superficial and deep and projected back to both \citep{RocklandPandya79,FellemanVanEssen91}.  Also, consistent with the core features of the pulvinar pathways discussed above, deep layer predictive (6CT) inputs originated in higher levels, while driver (5IB) inputs originated in lower levels.  For simplicity we organized the model layers in terms of these driver inputs, whereas the topographic organization of pulvinar in the brain is organized more according to the 6CT projection loops \citep{Shipp03}.

Another important set of parameters are the strength of deep-layer recurrent projections, which influence the timescale of temporal integration, producing a simple biologically-based version of \emph{slow feature analysis} \citep{WiskottSejnowski02,Foldiak91}. We followed the biological data suggesting that recurrence increases progressively up the visual hierarchy \citep{ChaudhuriKnoblauchGarielEtAl15}.  It was essential that the \emph{Where} pathway learn first, consistent with extant data \citep{BourneRosa06,KiorpesPriceHall-HaroEtAl12}, including early pathways interconnecting LIP and pulvinar \citep{BridgeLeopoldBourne16}, and a rare asymmetric pathway, from V1 to LIP \citep{MarkovErcsey-RavaszGomesEtAl14}, providing a direct short-cut for high-level spatial representations in LIP.  Results from various informative model architecture and parameter manipulations are discussed below after the primary results from the standard intact model.  Learning curves and other model details are shown in the Appendix.  We have also implemented a full {\em de-novo} replication of the model in a new modeling framework, which also replicated the results shown here (see Appendix for more details).  Furthermore, much of the model was originally developed in the context of a set of object-like patterns generated systematically from a set of simple line features, indicating the general applicability of this architecture.

\begin{figure}
  \centering\includegraphics[width=2in]{figs/fig_deepleabra_wwi_simat_over_lays}
  \caption{\footnotesize Emergence of abstract category structure over the hierarchy of layers, comparing similarity structure in each layer vs that present in V1 (black line) or in TE (red line).  Both cases, which are roughly symmetric, clearly show that IT layers (TEO, TE) progressively differentiate from raw input similarity structure present in V1, and, critically, that the model has learned structure beyond that present in the input.  This is is the simplest, most objective summary statistic showing this progressive emergence of structure, while subsequent figures provide a more concrete sense of what kinds of representations actually developed.}
  \label{fig.simat-lays}
\end{figure}

To directly address the question of whether the hierarchical structure of the network supports the development of abstract, higher-level representations that go beyond the information present in the visual inputs, we applied a second-order similarity measure across the object-level similarity matrices computed at each layer in the network (Figure~\ref{fig.simat-lays}).  This shows the extent to which the similarity matrix across objects in one layer is itself similar to the object similarity matrix in another layer, in terms of a correlation measure across these similarity matrices.  Critically, this measure does not depend on any kind of subjective interpretation of the learned representations --- it just tells us whether whatever similarity structure was learned differs across the layers.  Starting from either V1 compared to all higher layers, or the highest TE layer compared to all lower layers, we found a consistent pattern of progressive emergence of the object categorization structure in the upper IT pathway (TEO, TE). 

This analysis confirms that indeed the IT category structure is significantly different from that present at the level of the V1 primary visual input.  Thus the model, despite being trained only to generate accurate visual input-level predictions, has learned to represent these objects in an abstract way that goes beyond the raw input-level information.  We further verified that at the highest IT levels in the model, a consistent, spatially-invariant representation is present across different views of the same object (e.g., the average correlation across frames within an object was .901).

\begin{figure}
  \centering\includegraphics[width=5in]{figs/fig_deepleabra_wwi_rsa_leabra_expt1_objs}
  \caption{\footnotesize {\bf a)} Category similarity structure that developed in the highest layer, TE, of the biologically based predictive learning model, showing \emph{correlation distance} (1-correlation) similarity of the TE representation for each 3D object against every other 3D object (156 total objects).  Blue cells have high similarity, and model has learned block-diagonal clusters or categories of high-similarity groupings, contrasted against dissimilar off-diagonal other categories.  Clustering maximized average \emph{within -- between} correlation distance (see Appendix), and clearly corresponded to the shown shape-based categories, with exemplars from each category shown.  Also, all items from the same basic-level object categories (N=20) are reliably subsumed within learned categories. {\bf b)} Human similarity ratings for the same 3D objects, presented with the V1 reconstruction (see Fig 1b) to capture coarse perception in the model, aggregated by 20 basic-level categories (156 x 156 matrix was too large to sample densely experimentally).  Each cell is 1 - proportion of time given object pair was rated more similar than another pair (see Appendix).  The human matrix shares the same centroid categorical structure as the model (confirmed by permutation testing and agglomorative cluster analysis, see Appendix), indicating that human raters used the same shape-based category structure.}
  \label{fig.rsa}
\end{figure}

To better understand the nature of these learned representations, Figure~\ref{fig.rsa} shows a representational similarity analysis (RSA) on the activity patterns at each layer in the model, which reveals the explicit categorical structure of the learned representations \citep{KriegeskorteMurBandettini08,CadieuHongYaminsEtAl14}.  As shown in Figure~\ref{fig.rsa}a, we found that the highest IT layer (TE) produced a systematic organization of the 156 3D objects into 5 categories.  In our admittedly subjective judgment, these categories seemed to correspond to the overall shape of the objects, as shown by the object exemplars in the figure (pyramid-shaped, vertically-elongated, round, boxy / square, and horizontally-elongated).  Furthermore, the basic-level categories were subsumed within these broader shape-level categories, so the model appears to be sensitive to the coherence of these basic-level categories as well, but apparently their shapes were not sufficiently distinct between categories to drive differentiated TE-level representations for each such basic-level category.

Given that the model only learns from a passive visual experience of the objects, it has no access to any of the richer interactive multi-modal information that people and animals would have.  Furthermore, as evident in Figure~\ref{fig.model}b, the relatively low resolution of the V1 layers (required to make the model tractable computationally) means that complex visual details are not reliably encoded (and even so, are not generally reliable across object exemplars), such that the overall object shape is the most salient and sensible basis for categorization for this model.

Although these object shape categories appeared sensible to us, we ran a simple experiment to test whether a sample of 30 human participants would use the same category structure in evaluating the pairwise similarity of these objects.  Figure~\ref{fig.rsa}b shows the results, confirming that indeed this same organization of the objects emerged in their similarity judgments.  These judgments were based on the V1 reconstruction as shown in Figure~\ref{fig.model}b to capture the model's coarse-grained perception; see Appendix for methods and further analysis.

\begin{figure}
  \centering\includegraphics[width=4in]{figs/fig_deepleabra_wwi_rsa_leabra_macaque}
  \caption{\footnotesize Comparison of progression from V4 to IT in macaque monkey visual cortex (top row, from Cadieu et al., 2014) versus same progression in model (replotted using comparable color scale).  Although the underlying categories are different, and the monkeys have a much richer multi-modal experience of the world to reinforce categories such as foods and faces, the model nevertheless shows a similar qualitative progression of stronger categorical structure in IT, where the block-diagonal highly similar representations are more consistent across categories, and the off-diagonal differences are stronger and more consistent as well (i.e., categories are also more clearly differentiated).  Note that the critical difference in our model versus those compared in Cadieu et al. 2014 and related papers is that they explicitly trained their models on category labels, whereas our model is \emph{entirely self-organizing} and has no external categorical training signal.}
  \label{fig.macaque}
\end{figure}

The progressive emergence of increasingly abstract category structure across visual areas, evident in Figure~\ref{fig.simat-lays}, has been investigated in recent comparisons between monkey electrophysiological recordings and deep convolutional neural networks (DCNNs), which provide a reasonably good fit the the overall progressive pattern of increasingly categorical organization \citep{CadieuHongYaminsEtAl14}.  However, these DCNNs were trained on large datasets of human-labeled object categories, and it is perhaps not too surprising that the higher layers closer to these category output labels exhibited a greater degree of categorical organization --- this is an intrinsic property of the error backpropagation gradients.  In contrast, because the only source of learning in our model comes from prediction errors over the V1 input layers, the graded emergence of an object hierarchy here reflects a truly self-organizing learning process.

Figure~\ref{fig.macaque} compares the similarity structures in layers V4 and IT in macaque monkeys \citep{CadieuHongYaminsEtAl14} with those in corresponding layers in our model.  In both the monkeys and our model, the higher IT layer builds upon and clarifies the noisier structure that is emerging in the earlier V4 layer, showing that our model replicates the essential qualitative hierarchical progression in the brain.  As noted, we would not expect our model to exactly replicate the detailed object-specific similarity structure found in macaques, due to the impoverished nature of our model's experience, so this comparison remains qualitative in terms of the respective differences between V4 and IT in each model, rather than a direct comparison of the similarity structure between corresponding layers in the model and the macaque.  In the future, when we can scale up our model and tune the attentional processing dynamics necessary to deal with cluttered visual scenes, we will be able to train our model on the same images presented to the macaques, and can provide this more direct comparison.

Finally, we did not use analyses based on decoding techniques, because with high-dimensional distributed neural representations, it is generally possible to decode many different features that are not otherwise compactly and directly represented \citep{FusiMillerRigotti16}.  In preliminary work using decoding in the context of the simpler feature-based input patterns, we indeed found that decoding was not a very sensitive measure of the differentiation of representations across layers, which is so clearly evident in Figure~\ref{fig.simat-lays}.  Thus, as advocates of the RSA approach have argued, measuring similarity structure evident in the activity patterns over a given layer generally provides a clearer picture of what that layer is explicitly encoding \citep{KriegeskorteMurBandettini08}.

In summary, the model learned an abstract category organization that reflects the overall visual shapes of the objects as judged by human participants, in a way that is invariant to the differences in motion, rotation, and scaling that are present in the V1 visual inputs.  We are not aware of any other model that has accomplished this signature computation of the ventral \emph{What} pathway in a purely self-organizing manner operating on realistic 3D visual objects, without any explicit supervised category labels.  Furthermore, our model does this using a learning algorithm directly based on detailed properties of the underlying biological circuits in this pathway, providing a coherent overall account.

\subsection{Backpropagation Comparison Models}

\begin{figure}
  \centering\includegraphics[width=3.5in]{figs/fig_deepleabra_wwi_bp_prednet_v1sim}
  \caption{\footnotesize Similarity of similarity structure across layers for the comparison backprop models, comparing each layer to the first layer.  {\bf a)} Backpropagation (Bp) model with the same What / Where structure as the biological model.  Unlike the biologically-based model (Figure~\ref{fig.simat-lays}) the higher IT layers (TE, TEO) do not diverge significantly from the similarity structure present in V1, indicating that the model has not developed abstractions beyond the structure present in the visual input.  Layer V3 is most directly influenced by spatial prediction errors, so it differs from both in strongly encoding position information.  {\bf b)} PredNet model, which has 6 layers.  The higher layers uniformly diverge from the lowest layer, likely due to the fact that higher layers only encode errors, not stimulus-driven positive representations of the input, which are only present in the first layer.  Aside from this large distinction (which is inconsistent for example with the overall similarity in neural coding between V1 and V2), there is no evidence of a cumulative development of abstraction in higher layers.}
  \label{fig.bpred-v1sim}
\end{figure}

\begin{figure}
  \centering\includegraphics[width=3.5in]{figs/fig_deepleabra_wwi_bp_prednet_simat}
  \caption{\footnotesize {\bf a)} Best-fitting category similarity for TE layer of the backpropagation (Bp) model with the same What / Where structure as the biological model.  Only two broad categories are evident, and the lower \emph{max} distance (0.3 vs. 1.5 in biological model) means that the patterns are much less differentiated overall.  {\bf b)} Best-fitting similarity structure for the PredNet model, in the highest of its layers (layer 6), which is more differentiated than Bp (max = 0.75) but also less cleanly similar within categories (i.e., less solidly blue along the block diagonal), and overall follows a broad category structure similar to V1. {\bf c)} The best fitting V1 structure, which has 2 broad categories and banana is in a third category by itself.  The lack of dark blue on the block diagonal indicates that these categories are relatively weak, and every item is fairly dissimilar from every other.  {\bf d)} The Bp TE similarity values from panel a shown in the same ordering as V1 from panel c, demonstrating how the similarity structure has not diverged very much, consistent with the results shown in Figure~\ref{fig.bpred-v1sim} --- the within -- between contrast differences are 0.0838 for panel a and 0.0513 for d --- see Appendix for details.}
  \label{fig.bpred}
\end{figure}

To help discern some of the factors that contribute to the categorical learning in our model, and provide a comparison with more widely-used error backpropagation models, we tested a backpropagation-based (Bp) version of the same \emph{What} vs. \emph{Where} architecture as our biologically-based predictive error model, and we also tested a standard \emph{PredNet} model \citep{LotterKreimanCox16} with extensive hyperparameter optimization (see Appendix).  Due to the constraints of backpropagation, we had to eliminate any bidirectional connectivity loops in the Bp version, but we were able to retain a form of predictive learning by configuring the V1p pulvinar layer as the final target output layer, with the target being the next visual input relative to the V1 inputs.

Figure~\ref{fig.bpred-v1sim} shows the same second-order similarity analysis as Figure~\ref{fig.simat-lays}, to determine the extent to which these comparison networks also developed more abstract representations in the higher layers that diverge from the similarity structure present in the lowest layers.  According to this simple objective analysis, they did not --- the higher layers showed no significant divergence in their similarity structure relative to the lowest layer.  Next, we examined the RSA matrices for the highest (TE) layer in the comparison models, also in comparison with the same for the V1 layer (Figure~\ref{fig.bpred}).  This shows that the TE layer in the Bp model formed a simple binary category structure overall, which is similar to the RSA for the V1 input layer.  It is also important to emphasize that the scales on these figures are different (as shown in their headers), such that the Bp and PredNet models had much less differentiated representations overall.  Similar results were found in the PredNet model.  Because existing work with these models has typically relied on additional supervised learning and decoder-based analyses (which are essentially equivalent to an additional layer of supervised learning), these RSA-based analyses provide an important, more sensitive way of determining what they learn purely through predictive learning.

These results show that the additional biologically derived properties in our model are playing a critical role in the development of abstract categorical representations that go beyond the raw visual inputs. These properties include: excitatory bidirectional connections, inhibitory competition, and an additional Hebbian form of learning that serves as a regularizer (similar to weight decay) on top of predictive error-driven learning \citep{OReilly98,OReillyMunakata00}.  Each of these properties could promote the formation of categorical representations. Bidirectional connections enable top-down signals to consistently shape lower-level representations, creating significant attractor dynamics that cause the entire network to settle into discrete categorical attractor states.  Another indication of the importance of bidirectional connections is that a greedy layer-wise pretraining scheme, consistent with a putative developmental cascade of learning from the sensory periphery on up \citep{ShragerJohnson96,BengioYaoAlainEtAl13,Valpola14,HintonSalakhutdinov06}, did not work in our model. Instead, we found it essential that higher layers, with their ability to form more abstract, invariant representations, interact and shape learning in lower layers right from the beginning.

Furthermore, the recurrent connections within the TEO and TE layers likely play an important role by biasing the temporal dynamics toward longer persistence \citep{ChaudhuriKnoblauchGarielEtAl15}.  By contrast, backpropagation networks typically lack these kinds of attractor dynamics, and this could contribute significantly to their relative lack of categorical learning.  Hebbian learning drives the formation of representations that encode the principal components of activity correlations over time, which can help more categorical representations coalesce (and results below already indicate its importance).  Inhibition, especially in combination with Hebbian learning, drives representations to specialize on more specific subsets of the space.

Ongoing work is attempting to determine which of these is essential in this case (perhaps all of them) by systematically introducing some of these properties into the backpropagation model, though this is difficult because full bidirectional recurrent activity propagation, which is essential for conveying error signals top-down in the biological network, is incompatible with the standard efficient form of error backpropagation, and requires significantly more computationally intensive and unstable forms of fully recurrent backpropagation \citep{WilliamsZipser92,Pineda87}.  Furthermore, Hebbian learning requires dynamic inhibitory competition which is difficult to incorporate within the backpropagation framework.

\subsection{Architecture and Parameter Manipulations}

\begin{figure}
  \centering\includegraphics[width=5in]{figs/fig_deepleabra_wwi_leabra_manips}
  \caption{\footnotesize Effects of various manipulations on the extent to which TE representations differentiate from V1.  For all plots, \emph{Intact} is the same result shown in Figure~\ref{fig.simat-lays} from the intact model for ease of comparison.  All of the following  manipulations significantly impair the development of abstract TE categorical representations (i.e., TE is more similar to V1 and the other layers).  {\bf a)} Dorsal \emph{Where} pathway lesions, including lateral inferior parietal sulcus (LIP), V3, and dorsal prelunate (DP).  This pathway is essential for regressing out location-based prediction errors, so that the residual errors concentrate feature-encoding errors that train the \emph{What} pathway.  {\bf b)} Allowing the deep layers full access to current-time information, thus effectively eliminating the prediction demand and turning the network into an auto-encoder, which significantly impairs representation development, and supports the importance of the challenge of predictive learning for developing deeper, more abstract representations.  {\bf c)} Reducing the strength of Hebbian learning by 20\% (from 2.5 to 2), demonstrating the essential role played by this form of learning on shaping categorical representations.  Eliminating Hebbian learning entirely (not shown) prevented the model from learning anything at all, as it also plays a critical regularization and shaping role on learning.}
  \label{fig.manips}
\end{figure}

Figure~\ref{fig.manips} shows just a few of the large number of parameter manipulations that have been conducted to develop and test the final architecture.  For example, we hypothesized that separating the overall prediction problem between a spatial \emph{Where} vs. non-spatial \emph{What} pathway \citep{UngerleiderMishkin82,GoodaleMilner92}, would strongly benefit the formation of more abstract, categorical object representations in the \emph{What} pathway.  Specifically, the \emph{Where} pathway can learn relatively quickly to predict the overall spatial trajectory of the object (and anticipate the effects of saccades), and thus effectively regress out that component of the overall prediction error, leaving the residual error concentrated in object feature information, which can train the ventral \emph{What} pathway to develop abstract visual categories.  Figure~\ref{fig.manips}a shows that, indeed, when the \emph{Where} pathway is lesioned, the formation of abstract categorical representations in the intact \emph{What} pathway is significantly impaired.  Figure~\ref{fig.manips}b shows that full predictive learning, as compared to just encoding and decoding the current state (i.e., an auto-encoder, which is much easier computationally, and leads to much better overall accuracy), is also critical for the formation of abstract categorical representations --- prediction is a ``desirable difficulty'' \citep{Bjork94}.  Finally, Figure~\ref{fig.manips}c shows the impact of reducing Hebbian learning, which impairs category learning as expected.

\subsection{Predictive Behavior}

\begin{figure}
  \centering\includegraphics[width=4in]{figs/fig_deepleabra_wwi_pred_remap_untraj_vs_data}
  \caption{\footnotesize Predictive Remapping.  {\bf top:} Original remapping data in LIP from Duhamel et al (1992).  A) shows stimulus (star) response within receptive field (dashed circle) relative to fixation dot (upper right of fixation).  B) Just prior to monkey making a saccade to new fixation (moving left), stimulus is turned on in receptive field location that {\em will be} upper right of the new fixation point, and the LIP neuron responds to that stimulus in advance of the saccade completing.  The neuron does not respond to the stimulus in that location if it is not about to make a saccade that puts it within its receptive field (not shown).  This is predictive remapping.  C) response to the old stimulus location goes away as saccade is initiated.  {\bf bottom:} Data from our model, from individual units in LIPd, V2d, and V2s, showing that the LIP deep neurons respond to the saccade first, activating in the new location and deactivating in the old, and this LIP activation goes top-down to V3 and V2 to drive updating there, generally at a longer latency and with less activation especially in the superficial layers.  When the new stimulus appears at the point of fixation (after a 50 msec saccade here), the {\em primed} V2s units get fully activated by the incoming stimulus.  But the deep neurons are insulated from this superficial input until the plus phase, when the cascade of 5IB firing drives activation of the actual stimulus location into the pulvinar, which then reflects up into all the other layers.}
  \label{fig.remap_units}
\end{figure}

A signature example of predictive behavior at the neural level in the brain is the {\em predictive remapping} of visual space in anticipation of a saccadic eye movements \citep{DuhamelColbyGoldberg92,ColbyDuhamelGoldberg97,GottliebKusunokiGoldberg98,NakamuraColby02,MarinoMazer16} (Figure~\ref{fig.remap_units}a).  Here, parietal neurons start to fire at the {\em future} receptive field location where a currently-visible stimulus will appear after a planned saccade is actually executed. Remapping has also been shown for border ownership neurons in V2 \citep{OHerronHeydt13} and in area V4 \citep{NeupaneGuittonPack16,NeupaneGuittonPack20}. These are examples, we believe, of a predictive process operating throughout the neocortex to predict what will be experienced next.  A major consequence of this predictive process is the perception of a stable, coherent visual world despite constant saccades and other sources of visual change. 

Figure~\ref{fig.remap_units}b shows that our model exhibits this predictive remapping phenomenon.  Specifically, LIP, which is most directly interconnected with the saccade efferent copy signals, is the first to predict the new location, and it then drives top-down activation of lower layers.  This top-down dynamic is consistent with the account of predictive remapping given by \citet{Wurtz08} and \citet{CavanaghHuntAfrazEtAl10}, who argue that the key remapping takes place at the high levels of the dorsal stream, which then drive top-down activation of the predicted location in lower areas, instead of the alternative where lower-levels remap themselves based on saccade-related signals.  The lower-level visual layers are simply too large and distributed to be able to remap across the relevant degrees of visual angle --- the extensive lateral connectivity needed to communicate across these areas would be prohibitive.

\section{Neural Data and Predictions}

Having tested the computational and functional learning properties of this biologically-based predictive learning mechanism, we now return to consider some of the most important neural data of relevance to our hypotheses, beyond that summarized in the introduction, including contrasts with a widely-discussed alternative framework for predictive coding, and some of the extensive data on alpha frequency effects, followed by a discussion of predictions that would clearly test the validity of this framework.

\subsection{Additional Neuroscience Data}

We begin with data relevant to the basic neural-level properties of the framework.  First, direct electrophysiological recording of deep layer neurons shows periodic alpha-scale bursting for continuous tones {\em in awake animals} \citep{LuczakBarthoHarris09,LuczakBarthoHarris13,SakataHarris09,SakataHarris12}.  {\em In vitro}, a variety of potential mechanisms behind the generation and synchronization of the 5IB bursts driving this alpha cycle have been identified \citep{ConnorsGutnickPrince82,SilvaAmitaiConnors91,FranceschettiGuatteoPanzicaEtAl95}.  Furthermore, the pulvinar has been shown to drive alpha-frequency synchronization of cortical activity across areas in the alpha band in awake behaving animals \citep{SaalmannPinskWangEtAl12}.  We review the larger alpha frequency literature in more detail below, but it is critical to emphasize that this alpha bursting dynamic is actually found in awake, behaving animals, because so many other bursting and up / down state phenomena have recently been shown to only occur in anesthetized brains, including bursting in the pulvinar itself, as we discuss below.

The 6CT neurons exhibit regular spiking behavior, in contrast to the 5IB bursting \citep{Thomson10,ThomsonLamy07}. Also, they do not have axonal branches that project to other cortical areas --- the subpopulation that projects to the pulvinar only project there and not to other cortical areas \citep{PetrofViaeneSherman12}, whereas there are other layer 6 neurons that do project to other cortical areas.  This distinct connectivity is consistent with a specific role of this neuron type in generating predictions in the pulvinar.   The 6CT synaptic inputs on pulvinar TRCs have metabatropic glutamate receptors (mGluR) that have longer time-scale temporal dynamics consistent with the alpha period (100 msec) and even longer \citep{Sherman14}, and the 6CT neurons themselves also have temporally-delayed responding \citep{HarrisShepherd15,SakataHarris09,Thomson10}.  Furthermore, they have significantly more plasticity-inducing NMDA receptors compared to the 5IB projections \citep{UsreySherman18}.  These properties are consistent with the 6CT inputs driving a longer-integrated prediction signal that is subject to learning, whereas the 5IB are likely non-plastic and their effects are tightly localized in time. 

The 5IB inputs often have distinctive \emph{glomeruli} structures at their synapses onto pulvinar neurons, which contain a complete feedforward inhibition circuit involving a local inhibitory interneuron, in addition to the direct strong excitatory driver input \citep{WilsonBoseShermanEtAl84}.  Computationally, this can provide a balanced level of excitatory and inhibitory drive so as to not overly excite the receiving neuron, while still dominating its firing behavior.

Although there are well-documented and widely-discussed burst vs. tonic firing modes in pulvinar neurons \citep{ShermanGuillery06}, there is not much evidence of these playing a clear role in the awake, behaving state, and as noted earlier the growing electrophysiological evidence shows a remarkable correspondence between cortical and pulvinar response properties across multiple different pulvinar areas in this awake state.  Nevertheless, there may be important dynamics arising from these firing modes that are more subtle or emerge in particular types of state transitions that may have yet to be identified.

\subsection{Contrast with Explict Error (EE) Frameworks}

\begin{figure}
  \centering\includegraphics[width=4in]{figs/fig_deepleabra_pred_vs_explicit_err}
  \caption{\footnotesize Comparison between: {\bf a)} The proposed thalamocortical temporal-difference predictive learning model (from Figure~1), versus {\bf b)} The Bayesian-style explicit error (EE) coding model (Rao \& Ballard, 1999; Friston, 2010, Bastos et al., 2012), in a situation where the prediction is clearly erroneous (ball predicted to emerge on right, actually emerges on left).  The EE model holds that superficial (2/3) error-coding neurons receive the prediction via a net inhibitory top-down projection from higher-level deep layer neurons, and an excitatory bottom-up projection representing the outcome, such that their activation represents the difference.  To encode both signs of the error (omissions, false alarms) with positive-only spike rates, two separate populations of EE neurons would be required, or a more complicated deviation from tonic firing level scheme.  Unambiguous evidence of such EE coding neurons has not been found (Walsh et al, 2020).  In contrast, error signals in our proposed framework remain as a temporal difference between the two states of prediction vs. outcome, \emph{which enables all connectivity between cortical areas to be excitatory and always represent a positive encoding of either the prediction or outcome}.  In contrast, under EE, after one error subtraction at the lowest level, only error signals are hypothesized to flow forward to higher layers, meaning that the representations at higher layers are about increasingly higher-order \emph{errors}, not positive encodings of the environmental state at increasing levels of abstraction.  This is inconsistent with extensive available data.  For this illustration, V1 is assumed to be like a clamped input layer, not subect to predictive learning itself.}
  \label{fig.ee}
\end{figure}

To further clarify the nature of the present theory, and introduce a body of relevant data, it is important to contrast it with the widely-discussed explicit error (\emph{EE}) framework for predictive coding \citep{RaoBallard99,KawatoHayakawaInui93,Friston05,Friston10,OudenKokLange12,BastosUsreyAdamsEtAl12,LotterKreimanCox16} (Figure~\ref{fig.ee}).  Despite many attempts to identify such explicit error-coding neurons in the cortex, no substantial body of unambiguous evidence has been discovered \citep{KokLange15,KokJeheedeLange12,SummerfieldEgner09,LeeMumford03,WalshMcGovernClarkEtAl20}.  Furthermore, due to the positive-only firing rate nature of neural coding, two separate populations would be required to convey both signs of prediction error signals, or it would have to be encoded as a variation from tonic firing levels, which are generally low in the neocortex.

By contrast, the use of temporal-difference error signals enables all connections between cortical layers to be excitatory and each layer can represent the positive encoding of either the prediction or outcome state, at different levels of abstraction.  These properties are overwhelmingly supported by extensive electrophysiological data about the hierarchical organization of representations, e.g., in the visual object recognition pathway \citep{KobatakeTanaka94,VanRullenThorpe02,CadieuHongYaminsEtAl14}, and are consistent with the widely-supported biased competition model for excitatory top-down attentional effects \citep{DesimoneDuncan95,ReynoldsChelazziDesimone99,MillerCohen01,OReillyWyatteHerdEtAl13}.

By contrast, the EE approach requires net inhibitory top-down predictions, and it sends error signals forward, not positive representations of the actual state at a given level of abstraction.  Thus a literal interpretation (and at least one existing implementation; \citealp{LotterKreimanCox16}) has only error signals represented at all levels above the lowest level, which is inconsistent with the positive encoding of stimuli at various levels of abstraction across the visual hierarchy.  For example, although \citet{IssaCadieuDiCarlo18} observed an error-signal-like increase in activation for atypical faces in some pIT neurons, these neurons overall had a positive stimulus encoding, with only a relatively small, later, error-like modulation.

Furthermore, as discussed below, anticipatory predictions typically closely resemble the subsequent stimulus-driven activity, suggesting a positive, not inhibitory, effect  \citep{DuhamelColbyGoldberg92,LeeMumford03,CavanaghHuntAfrazEtAl10,WalshMcGovernClarkEtAl20}.  However, there are various different ways of reformulating the neural implementation of EE that can avoid some of these issues \citep{Spratling08,BastosUsreyAdamsEtAl12}, but perhaps this flexibility renders the framework difficult to falsify \citep{KogoTrengove15}.  In any case, an extensive treatment of the issues with EE is beyond the scope of this paper and has already been aptly covered by \citet{WalshMcGovernClarkEtAl20} --- our goal here is to highlight some of the core differences as a way to clarify the framework by way of contrast, and in relation to available data.

First, there are many examples of anticipatory predictive neural firing in the brain.  Of perhaps greatest relevance, \citet{BarczakOConnellMcGinnisEtAl18} recently showed that the auditory pulvinar in monkeys exhibits predictive firing using a carefully controlled auditory sequence that had no first-order acoustic differences from a background noise signal.  The pulvinar predictive activation preceded that of A1, suggesting a strong predictive role for pulvinar.  Unfortunately, the deep layers of higher auditory areas that should contribute to the formation of the pulvinar prediction were not recorded in this study, so their role in generating the prediction could not be determined.

Nevertheless, there is extensive additional evidence for top-down anticipatory activation of predicted stimuli, with activity patterns closely resembling the subsequent stimulus-driven ones \citep{WalshMcGovernClarkEtAl20}.  For example, the widely replicated predictive remapping effect, simulated in our model (Figure~\ref{fig.remap_units}) is of this nature \citep{DuhamelColbyGoldberg92,Wurtz08,CavanaghHuntAfrazEtAl10}.  The fact that these anticipatory activations are of a positive nature, consistent with the stimulus-driven activations, is inconsistent with the expected behavior of EE neurons, which should be inhibited by the top-down prediction, while not receiving any bottom-up stimulus.

However, the neural response to the actual predicted stimulus itself is typically suppressed relative to unexpected stimuli, i.e., \emph{expectation suppression} \citep{SummerfieldTrittschuhMontiEtAl08,TodorovicEdeMarisEtAl11,MeyerOlson11,BastosUsreyAdamsEtAl12}.  This phenomenon is widely cited as evidence in favor of the EE predictive coding framework, consistent with an inhibitory effect of the expectation.  Nevertheless, despite various conflicting results and many complications of interpretation, multiple comprehensive reviews conclude that it is difficult to distinguish expectation suppression from the neural adaptation effects that underlie the well-documented \emph{repetition suppression} effect \citep{WalshMcGovernClarkEtAl20,VinkenVogels17,KokLange15,KokJeheedeLange12,SummerfieldEgner09,LeeMumford03}.  Furthermore, detailed single-neuron level recordings are the least likely to show these effects --- instead, they are most evident in aggregate signals such as the BOLD response in fMRI, suggesting that they may more strongly reflect population-level differences in activity, rather than individual explicit error coding neurons.

As noted earlier, accurately predicted outcomes in our framework would result in a continued adaptation of the neural response carrying over from the prediction to the outcome state, whereas unexpected outcomes would be associated with two distinct patterns of activity over a given area: first the prediction and then the outcome.  Thus, the unexpected outcome state would not be subject to the prior neural adaptation effects, and furthermore the time-integrated aggregate activity over these two patterns would be greater compared to the single activity state associated with an accurately predicted outcome.  Thus, our model explains expectation suppression without invoking EE neurons, meaning that considerably more detailed and replicable experimental paradigms using single-neuron resolution techniques are needed to distinguish EE from our framework.

\subsection{Alpha Frequency Effects}

The alpha frequency bursting of 5IB neurons acting as drivers into the pulvinar naturally entrains the predictive learning process in our model to this fundamental rhythm, which has long been recognized as an important signature of posterior cortical function \citep{Berger29,Walter53,NunnOsselton74,VarelaToroJohnEtAl81,VanRullenKoch03}.  A number of different functional associations with alpha have been established, and this literature is large and growing rapidly.  Thus, we refer the reader to recent reviews \citep{JensenBonnefondMarshallEtAl15,VanRullen16,ClaytonYeungKadosh18,FosterAwh19} while highlighting the data most relevant to our specific framework here, organized according to a set of key points.

\begin{itemize}
	\item \emph{Alpha is specifically associated with deep neocortical layers and the pulvinar, and with feedback pathways in the cortex.}  This has been established using direct laminar-specific electrophysiological single-neuron and local field potential (LFP) recordings \citep{LuczakBarthoHarris13,BuffaloFriesLandmanEtAl11,MaierAdamsAuraEtAl10,MaierAuraLeopold11,SpaakBonnefondMaierEtAl12,XingYehBurnsEtAl12}, and feedforward vs. feedback manipulations \citep{vonSteinChiangKonig00,vanKerkoerleSelfDagninoEtAl14,BastosVezoliBosmanEtAl15,JensenBonnefondMarshallEtAl15,MichalareasVezolivanPeltEtAl16}.  	These data are consistent with the 5IB alpha bursting and the major role of cortical deep layers in driving top-down corticocortical projections (in addition to the 6CT pathway which is specific to the pulvinar).  By contrast, these same papers show that superficial cortical layers are associated with gamma frequency (40 Hz) dynamics.  Overall, these data suggest that noninvasive EEG methods could provide a direct window onto the predictive learning process.  However, the next point raises some important interpretational difficulties.
	
	\item \emph{Increases in cortical activity levels, e.g., due to attention, produce a corresponding decrease in alpha power, while decreased activity increases alpha power}  \citep{WordenFoxeWangEtAl00,KellyLalorReillyEtAl06,KlimeschSausengHanslmayr07,FriesWomelsdorfOostenveldEtAl08,JensenMazaheri10,FosterAwh19}. This pattern is not exactly what you might expect if alpha was a signature of predictive learning.  However, given that these same pulvinar and thalamocortical pathways are also widely regarded as important for attention \citep{LaBergeBuchsbaum90,BenderYouakim01,SnowAllenRafalEtAl09,SaalmannKastner11,ZhouSchaferDesimone16,FiebelkornKastner19}, this pattern presents a challenge for many theorists.  However, it is possible to explain this pattern as arising directly from the desynchronizing effects of cortical activity on alpha power.  Specifically, neural spiking is associated with broadband noise, due to the highly random, Poisson nature of spike firing, which can desynchronize the entrainment of lower-frequency oscillations including alpha \citep{WaldertLemonKraskov13,RayMaunsell11,PrivmanMalachYeshurun13,SolomonKragelSperlingEtAl17}.  In other words, because cortical activity is inherently noisy, it tends to interfere with the coherent activity across populations of neurons needed to produce a strong alpha frequency power signal.  This explanation is directly supported by studies manipulating and measuring cortical activity \citep{ZhouSchaferDesimone16,FriesWomelsdorfOostenveldEtAl08}, and is consistent with alpha power changes being a \emph{result} of attentional modulation, but not their cause \citep{AntonovChakravarthiAndersen20}.  Thus, while attention and predictive learning can both affect overall activity levels in cortex, and thus drive changes in alpha power, alpha power itself is not a transparent measure of the underlying mechanisms supporting these functions, which may help to explain some contradictory patterns of results \citep{FosterAwh19,GundlachMorattiForschackEtAl20,KeitelKeitelBenwellEtAl19}.
	
	\item \emph{Alpha phase effects provide a more direct measure of thalamocortical function than alpha power, and have been more consistently related to perception, attention, and prediction}  \citep{NunnOsselton74,VarelaToroJohnEtAl81,VanRullenKoch03,BuschDuboisVanRullen09,MathewsonFabianiGrattonEtAl10,PalvaPalva11,JaegleRo13,NeupaneGuittonPack17,Solis-VivancoJensenBonnefond18}.  For example, weak, near-threshold stimuli are more reliably detected and processed when presented in the trough of the individual's ongoing alpha cycle.  Of greatest relevance to the present paper are studies showing effects of prediction on alpha phase \citep{SamahaBauerCimaroliEtAl15,MayerSchwiedrzikWibralEtAl16,ShermanKanaiSethEtAl16}.  For example, \citet{MayerSchwiedrzikWibralEtAl16} showed that prestimulus alpha phase directly correlated with the predictability of the upcoming stimulus, and the pattern of this prestimulus activation was indistinguishable from the subsequent stimulus activation pattern.  This is consistent with our model, and less consistent with the EE framework, as discussed previously.  \citet{NeupaneGuittonPack17} found strong alpha coherence effects in LFP recordings distributed across V4, associated with the predictive remapping of receptive fields \citep{DuhamelColbyGoldberg92}.

	\item \emph{Discrete, salient, or oscillatory stimuli entrain the alpha cycle in the brain} \citep{SpaakLangeJensen14,MathewsonPrudhommeFabianiEtAl12}.  Furthermore, the massive literature on \emph{event related potentials} (ERPs) may represent a significant contribution from alpha-level entrainment \citep{MakeigWesterfieldJungEtAl02,GruberKlimeschSausengEtAl05,Klimesch11}.  These entrainment effects are consistent with the 5IB entrainment mechanisms in our framework, as described earlier, and entrainment is functionally important for aligning predictive learning with relevant salient or unexpected outcomes.

	\item \emph{The pulvinar contributes to synchronizing alpha phase relationships across different brain areas} \citep{SaalmannPinskWangEtAl12,FiebelkornPinskKastner18}.  This is consistent with the broad, convergent pattern of projections into the pulvinar from many different cortical areas, and the corresponding broad projections back out to these same areas \citep{Shipp03,ArcaroPinskKastner15}.  Functionally, this convergence and synchronization is important for integrating the contributions from these different areas at the same time, to generate predictions over the pulvinar.
	
	\item \emph{The theta cycle, comprised of a pair of alpha cycles, organizes saccades, and attentional, motor, and mnemonic processes} \citep{FiebelkornKastner19}.  The theta rhythm is dominant in the medial temporal lobe and hippocampus, and has been extensively studied there \citep{KahanaSeeligMadsen01,Buzsaki05}.  Furthermore, there is a  sharp peak of saccade fixation durations at 200 msec, which suggests that two alpha cycles are typically required for  complete processing of a given fixation.  On the first cycle, the predictions from before the eye moved may be fairly vague depending on factors such as the size of the saccade and familiarity with the environment.  But after the first alpha cycle of a fixation, a subsequent \emph{postdiction} phase can provide an important additional learning opportunity, to consolidate and more deeply encode the current fixation (computationally equivalent to an auto-encoder).  Also, a mix of smaller saccades (including microsaccades) and larger saccades enables a range of more and less predictable outcomes on the first alpha cycle after the saccade, and matches human behavior \citep{Martinez-CondeOtero-MillanMacknik13,Martinez-CondeMacknikHubel04}.
	
\end{itemize}

Putting all of these points together, a particularly effective way of testing the predictions of our framework would be measuring alpha phase changes emerging in the prestimulus period as a function of predictive learning in predictable sequential stimulus streams.  In addition, it would also be important to examine theta and alpha-cycle dynamics in relation to predictive learning in the context of attention, motor control, and memory processes, to better understand the larger systems-level temporal organization of learning and processing in the brain \citep{FiebelkornKastner19}.

\subsection{Predictions for Predictive Learning}

In this section, we enumerate a set of direct, testable predictions from our framework.  Before doing so, there are several important considerations for any experimental test of the theory.  First, the nature of what is to be learned must be matched to the pulvinar area in question.  For example, learning a new variation of basic physics in movies at the alpha time scale (e.g., altering properties such as gravity, inertia, or elasticity), would be appropriate for the lower level visual pathways.  At higher visual levels (e.g., IT cortex), it might be possible to use simple sequences of different objects, although it is not clear to what extent the hippocampus or prefrontal cortex might also contribute in this case \citep{GavornikBear14,FiserMahringerOyiboEtAl16}.  To distinguish pulvinar learning effects from pervasive motor learning supported by other brain areas, it would be most effective to directly measure activity in the pulvinar and / or associated perceptual neocortical areas, instead of involving overt behavioral performance. 

Much of the learning in posterior sensory cortex should take place early in development, requiring very early developmental interventions or genetic knockouts that are expressed from the start (which can also have other interpretational issues if not highly selective).  In our models, the bulk of the basic sensory predictive learning happens very quickly, because the basic first-level regularities are quite strong and relatively easily learned.  While there are longer-term changes in the higher-level pathways in our models, more fine-grained measurements would likely be required to see these changes.  Once this learning has taken place, the remaining contributions of the thalamocortical circuit are likely more strongly weighted toward its role in attention, as we discuss below.  Finally, directly lesioning or inactivating the pulvinar is not likely to be very informative, because existing work has shown dramatic effects on cortical activity \citep{ZhouSchaferDesimone16,PurushothamanMarionLiEtAl12}, and also any effects could be attributed to the attentional contributions of the pulvinar.

With these considerations in mind, here are a set of strong predictions from our model that should be testable using existing techniques.  Failure to obtain the predicted result, while adhering to all the relevant constraints, would constitute a falsification of our model.

\begin{itemize}
	\item \emph{Blocking 5IB bursting mechanisms early in developmental learning should disrupt learning}.  It should be possible to selectively knock out or modify the channels that cause this specific population of neurons to burst fire, and doing so should have a significant effect on learning in associated neocortical and pulvinar areas, given the critical role that this burst firing plays on the predictive learning process as elaborated above.

	\item \emph{Blocking synaptic plasticity in pulvinar (specifically the 6CT inputs) very early in developmental learning should impair learning}.  While most of the learning overall should occur in the neocortex as a result of the temporal difference error signal broadcast by the pulvinar (which should remain generally intact), learning in the 6CT projections is important, especially right at the start, to map the emerging neocortical representations into the space defined by the 5IB projections.
	
	\item \emph{Temporal differences on an alpha cycle timescale actually drive synaptic plasticity in an error-driven learning manner, in neocortical pyramidal neurons and in 6CT inputs to pulvinar}.  That is, if a pre / post pair of neurons across a synapse is more active in the prediction than the subsequent outcome, the synapse should experience LTD (long term depression), and vice-versa if the activity pattern is reversed (long term potentiation, LTP, for more activity in outcome than prediction).  Furthermore, if activity is essentially stable across both prediction and outcome phases, then weights should not change (modulo a small level of Hebbian learning; \citealp{OReillyMunakata00,OReillyMunakataFrankEtAl12}).  This should be directly testable using current  experimental methods, and is perhaps the single most important empirical test of this entire framework, and it also underlies many other current approaches to error-driven learning in the brain \citep{BengioMesnardFischerEtAl17,WhittingtonBogacz19,LillicrapSantoroMarrisEtAl20}.  One general consideration is the extent to which an awake \emph{in vivo} preparation would be required to capture all the neuromodulatory and other factors present when this learning normally takes place.  Some suggestive evidence in such a preparation is generally consistent with a sensitivity to relatively short-term temporal dynamics \citep{LimMcKeeWoloszynEtAl15}, although these results lacked the direct measurement of individual neural activity across a synapse.

\end{itemize}

\section{Discussion}

We have hypothesized a novel computational function for the distinctive features of thalamocortical circuits \citep{ShermanGuillery06,UsreySherman18}, as supporting a specific form of prediction-error driven learning, where predictions arise from the numerous top-down layer 6CT projections into the pulvinar, and the strong, sparse, focal driving 5IB inputs supply the bottom-up sensory-driven outcome. The phasic bursting nature of the 5IB inputs results in a natural temporal-difference error signal of prediction followed by outcome, consistent with extensive neural recording data.  This temporal dynamic is also essential for enabling predictions to be generated without contamination from current sensory inputs, and predicts a characteristic alpha frequency prediction cycle based on the 10hz bursting cycle of the 5IB inputs, consistent with the pervasive influence of alpha on perception and neural dynamics \citep{JensenBonnefondMarshallEtAl15,VanRullen16,ClaytonYeungKadosh18,FosterAwh19}.  In short, the hypothesized predictive learning function fits remarkably well with a number of well-established properties of these thalamocortical circuits, and we also provided a set of additional predictions that could be tested to further evaluate this theory, especially in contrast to the widely-discussed alternative of explicit error coding neurons, which have not been unambiguously supported across a range of empirical studies \citep{WalshMcGovernClarkEtAl20}.

Furthermore, we implemented this theory in a large scale model of the visual system, and demonstrated that learning based strictly on predicting what will be seen next is, in conjunction with a number of critical biologically motivated network properties and mechanisms, capable of generating abstract, invariant categorical representations of the overall shapes of objects.  The nature of these shape representations closely matches human shape similarity judgments on the same objects.  Thus, predictive learning has the potential to go beyond the surface structure of its inputs, and develop systematic, abstract encodings of the environment.   We found that comparison models based on standard error backpropagation learning did not learn a categorical structure that went beyond the surface similarity present in the visual input layers, and future work is focused on narrowing down the specific mechanisms required to drive this learning.

In addition to the predictive learning functions of the deep / thalamic layers, these same circuits are also likely critical for supporting powerful top-down attentional mechanisms that have a net multiplicative effect on superficial-layer activations \citep{BortoneOlsenScanziani14,OlsenBortoneAdesnikEtAl12,BortoneOlsenScanziani14,OlsenBortoneAdesnikEtAl12}. The importance of the pulvinar for attentional processing has been widely documented \cite[e.g.,]{LaBergeBuchsbaum90,BenderYouakim01,SaalmannPinskWangEtAl12}, and there is likely an additional important role of the thalamic reticular nucleus (TRN), which can contribute a surround-inhibition contrast-enhancing effect on top of the incoming attentional signal from the cortex \citep{Crick84,Pinault04,WimmerSchmittDavidsonEtAl15,JaramilloMejiasWang19}. In other work in progress, we have shown that the deep / thalamic circuits in our model produce attentional effects consistent with the abstract \citet{ReynoldsHeeger09} model, while the contributions of the deep layer networks to this function are broadly consistent with the folded-feedback model \citep{Grossberg99}.  These attentional modulation signals cause the bidirectional constraint satisfaction process in the superficial network to focus on task-relevant information while down-regulating responses to irrelevant information --- in the real world, there are typically too many objects to track at any given time, so predictive learning must be directed toward the most important objects \citep{Pylyshyn89,CavanaghHuntAfrazEtAl10,RichterdeLange19}.

There is also data suggesting that the pulvinar is important for supporting \emph{confidence} judgments, driven by relative ambiguity in a random dot motion categorization task \citep{KomuraNikkuniHirashimaEtAl13}.  Critically for the present framework, this confidence modulation only emerged in the period after the first 100 msec of processing, and manifested as a positive correlation with confidence (i.e., more unambiguous stimuli resulted in higher firing rates).  We can interpret this as reflecting an ongoing generative \emph{postdiction} of the stimulus signal, with stronger firing associated with more unambiguous top-down activation based on the current internal representation.  Note that this directionality is the opposite of explicit error-coding neurons, which would presumably increase with increasing error / ambiguity in the prediction.  Interestingly, inactivation of these pulvinar neurons resulted in a substantial (200\%) increase in opt-out choices on the most ambiguous stimuli, suggesting a level of metacognitive awareness of the pulvinar signal (or at least a direct effect of pulvinar on relevant metacognitive processes).  Predictive accuracy would be an ideal source of metacognitive confidence signals across a wide range of domains, suggesting another important contribution of pulvinar even after initial learning.  \citet{JaramilloMejiasWang19} present a comprehensive model of attentional, decision-making, and working memory contributions of the pulvinar, including this confidence data, which is generally compatible with our framework, although it does not address any learning phenomena.

% NOTE: trying to keep the discussion brief.  there are a number of things a longer discussion could address.

% issue of precision / uncertainty of prediction state!  Definitely a factor in most current theories: de Lange, Friston etc.

% auto-encoder: Current deep-neural-network auto-encoder models typically adopt a de-noising framework in order to avoid the network learning a degenerate ``mindless copying'' solution to the problem: the inputs are presented with noise added, and the network is trained to produce the de-noised version \citep{BengioYaoAlainEtAl13,Valpola14,RasmusBerglundHonkalaEtAl15}.  By contrast, prediction is sufficiently challenging already, and adding the dynamic, temporal aspect to the problem adds many important dimensions of relevance to the real-world survival of organisms, so we think it is overall a much more likely goal for biological learning.

Considerable further work remains to be done to more precisely characterize the essential properties of our biologically motivated model necessary to produce this abstract form of learning, and to further explore the full scope of predictive learning across different domains.  We strongly suspect that extensive cross-modal predictive learning in real-world environments, including between sensory and motor systems, is a significant factor in infant development and could greatly multiply the opportunities for the formation of higher-order abstract representations that more compactly and systematically capture the structure of the world \citep{YuSmith12}.  Future versions of these models could thus potentially provide novel insights into the fundamental question of how deep an understanding a pre-verbal human, or a non-verbal primate, can develop \citep{SpelkeBreinlingerMacomberEtAl92,ElmanBatesKarmiloff-SmithEtAl96}, based on predictive learning mechanisms.  This would then represent the foundation upon which language and cultural learning builds, to shape the full extent of human intelligence.

\clearpage

% \section{Supplemental Information}

\section{Appendix}

\input{deep_pred_lrn_2021_supp}

\clearpage

\bibliography{ccnlab}

\end{document}


